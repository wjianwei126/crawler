# Crawler Object

This project provide a variety of crawlers.

**Welcome anybody to provide pull requests and issues.**

- btdht-crawler: a spider in bt dht network and collects metadata of resources.


## Usage of btdht-crawler 

```shell
$ cd btdht-crawler/ 
$ pip install -r requirements.txt
$ python crawler.py
```

**Test environment:**

    cpu: Inter G3220
    mem: 8G
    network: 4Mbps, without dedicated IP
    OS: windows 10
    python: python2.7.9


In the test environment, the crawler cost 20% cpu and 20MB memory, collects 100 pieces metadata in 4 hours.



## Reference
Thanks those repo provide awsome ideas and beautiful code for me.

- [Fuck-You-GFW/simDHT](https://github.com/Fuck-You-GFW/simDHT.git)
- [78/ssbc](https://github.com/78/ssbc.git)


